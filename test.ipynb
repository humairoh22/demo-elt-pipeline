{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90b84480",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from sqlalchemy import inspect, create_engine\n",
    "from pipeline.utils.read_sql import read_sql_file\n",
    "from pipeline.utils.load_data import load_to_wh\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8542eeec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def db_conn():\n",
    "\n",
    "    try:\n",
    "        src_db = os.getenv(\"SRC_DB\")\n",
    "        src_host = os.getenv(\"SRC_HOST\")\n",
    "        src_user= os.getenv(\"SRC_USER\")\n",
    "        src_password = os.getenv(\"SRC_PASSWORD\")\n",
    "\n",
    "\n",
    "        dwh_db = os.getenv(\"DWH_POSTGRES_DB\")\n",
    "        dwh_host = os.getenv(\"DWH_POSTGRES_HOST\")\n",
    "        dwh_user = os.getenv(\"DWH_POSTGRES_USER\")\n",
    "        dwh_password = os.getenv(\"DWH_POSTGRES_PASSWORD\")\n",
    "        dwh_port = os.getenv(\"DWH_POSTGRES_PORT\")\n",
    "\n",
    "\n",
    "\n",
    "        src_conn = create_engine(f\"mysql+pymysql://{src_user}:{src_password}@{src_host}/{src_db}\")\n",
    "\n",
    "        # src_conn = mysql.connect(host=src_host,\n",
    "        #                  user=src_user,\n",
    "        #                  password= src_password,\n",
    "        #                  db= src_db)\n",
    "\n",
    "        dwh_conn = create_engine(f\"postgresql://{dwh_user}:{dwh_password}@{dwh_host}:{dwh_port}/{dwh_db}\")\n",
    "\n",
    "\n",
    "        return src_conn, dwh_conn\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error when connecting to database: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8e83f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# src_connection,_ = db_conn()\n",
    "\n",
    "# try:\n",
    "#     with src_connection.connect() as conn:\n",
    "#         print('berhasil konek')\n",
    "\n",
    "# except Exception as e:\n",
    "#     print(f'gagal konek: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bf7916e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(tablename: str, rename_col: dict = None):\n",
    "\n",
    "    src_engine,_ = db_conn()\n",
    "\n",
    "    # src_engine = demo_engine()\n",
    "\n",
    "    query = f\"SELECT * FROM {tablename}\"\n",
    "\n",
    "    read_query = pd.read_sql(query, con=src_engine)\n",
    "    \n",
    "    if rename_col:\n",
    "        read_query = read_query.rename(columns=rename_col)\n",
    "    \n",
    "    print(f\"Extract table {tablename} Success\")\n",
    "\n",
    "    return read_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5cdffae",
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_source = ['delivery_man',\n",
    "            'packinglist',\n",
    "             'transferstatus',\n",
    "             'deliveryproof',             \n",
    "             'customers',\n",
    "             'expedition',\n",
    "             'license_plate',\n",
    "             'office_address'\n",
    "             ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a364713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extract table delivery_man Success\n",
      "Load data to public.delivery_man success.\n",
      "\n",
      "Marked deleted records in public.delivery_man\n",
      "Extract table packinglist Success\n",
      "Load data to public.packinglist success.\n",
      "\n",
      "Marked deleted records in public.packinglist\n",
      "Extract table transferstatus Success\n",
      "Load data to public.transferstatus success.\n",
      "\n",
      "Marked deleted records in public.transferstatus\n",
      "Extract table deliveryproof Success\n",
      "Load data to public.deliveryproof success.\n",
      "\n",
      "Marked deleted records in public.deliveryproof\n",
      "Extract table customers Success\n",
      "Load data to public.customers success.\n",
      "\n",
      "Marked deleted records in public.customers\n",
      "Extract table expedition Success\n",
      "Load data to public.expedition success.\n",
      "\n",
      "Marked deleted records in public.expedition\n",
      "Extract table license_plate Success\n",
      "Load data to public.license_plate success.\n",
      "\n",
      "Marked deleted records in public.license_plate\n",
      "Extract table office_address Success\n",
      "Load data to public.office_address success.\n",
      "\n",
      "Marked deleted records in public.office_address\n"
     ]
    }
   ],
   "source": [
    "for tb_name in tb_source:\n",
    "    \n",
    "    RENAME_COL = {'no_invoice':'sj_numbers', \n",
    "                  'concat_inv':'no_sj', \n",
    "                  'pod':'pod_image', \n",
    "                  'timestamp':'pod_date',\n",
    "                  'created_at':'src_created_at',\n",
    "                  'update_at':'src_update_at'}\n",
    "    df = extract(tb_name, rename_col=RENAME_COL)\n",
    "    load_to_wh(df, tb_name, schema='public', track_deleted=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c22d6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_to_wh(df, tablename, key_col: list = None, schema: str = None):\n",
    "\n",
    "#     try:\n",
    "\n",
    "#         _, dwh_engine = db_conn()\n",
    "#         # dwh_engine = wh_engine()\n",
    "\n",
    "#         table_init = \"\"\n",
    "\n",
    "#         if schema:\n",
    "#             table_init += schema + \".\"\n",
    "\n",
    "#         table_init += tablename\n",
    "\n",
    "#         df_columns = list(df.columns)\n",
    "\n",
    "#         if not key_col:\n",
    "\n",
    "#             insp = inspect(dwh_engine)\n",
    "#             get_constraint_col = insp.get_unique_constraints(tablename, schema=schema)\n",
    "\n",
    "#             key_col = []\n",
    "#             for col in get_constraint_col:\n",
    "#                 key_col.extend(col['column_names'])\n",
    "\n",
    "#         match_col = \",\".join([f\"{col}\" for col in key_col])\n",
    "#         list_col_to_insert = \", \".join([f\"{col}\" for col in df_columns])\n",
    "#         list_col_to_update = [col for col in df_columns if col not in key_col]\n",
    "#         col_to_update = \", \".join([f'\"{col_name}\" = EXCLUDED.\"{col_name}\"' for col_name in list_col_to_update])\n",
    "        \n",
    "\n",
    "#         stmt = f\"\"\"\n",
    "#                 INSERT INTO {table_init} ({list_col_to_insert})\n",
    "#                 SELECT {list_col_to_insert} FROM temp_table\n",
    "#                 ON CONFLICT ({match_col}) DO\n",
    "#                 UPDATE SET\n",
    "#                 {col_to_update},\n",
    "#                 update_at = CURRENT_TIMESTAMP\n",
    "#                 \"\"\"\n",
    "        \n",
    "\n",
    "#         with dwh_engine.begin() as conn:\n",
    "\n",
    "#             conn.exec_driver_sql(\"DROP TABLE IF EXISTS temp_table\")\n",
    "#             conn.exec_driver_sql(\n",
    "#                 f\"CREATE TEMPORARY TABLE temp_table AS SELECT * FROM {table_init} WHERE false\"\n",
    "#             )\n",
    "\n",
    "#             df.to_sql(\"temp_table\", conn, if_exists='append', index=False)\n",
    "\n",
    "#             conn.exec_driver_sql(stmt)\n",
    "\n",
    "#             print(f\"Load data to table {table_init} success.\")\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error when loading data to table {tablename}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54177f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_columns = list(df.columns)\n",
    "key_col = ['packinglist_id']\n",
    "table_init = 'stg_demo.packinglist'\n",
    "\n",
    "match_col = \",\".join([f\"{col}\" for col in key_col])\n",
    "list_col_to_insert = \", \".join([f\"{col}\" for col in df_columns])\n",
    "list_col_to_update = [col for col in df_columns if col not in key_col]\n",
    "col_to_update = \", \".join([f'\"{col_name}\" = EXCLUDED.\"{col_name}\"' for col_name in list_col_to_update])\n",
    "\n",
    "\n",
    "stmt = f\"\"\"\n",
    "        INSERT INTO {table_init} ({list_col_to_insert})\n",
    "        SELECT * FROM temp_table\n",
    "        ON CONFLICT ({match_col}) DO\n",
    "        UPDATE SET\n",
    "        {col_to_update}\n",
    "        \"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
